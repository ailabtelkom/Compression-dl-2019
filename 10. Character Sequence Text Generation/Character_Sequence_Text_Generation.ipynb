{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Character_Sequence_Text_Generation.ipynb","provenance":[{"file_id":"1f-lJklJLif14NGxrmmWyrPqPQ56qglix","timestamp":1572166577934},{"file_id":"19aDfJXPTW0-M_gg3AVlo8cj1ta2KT_Rt","timestamp":1571239997885}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ge7xUW-DfDnh","colab_type":"text"},"source":["![alt text](https://anvaqta.id/headerai.jpg \"Compression.dl\")"]},{"cell_type":"markdown","metadata":{"id":"ZJBqsX-Uuyq5","colab_type":"text"},"source":["# Character Sequence Text Generation\n","\n","Di sini kita akan membuat language model untuk membangkitkan text dari level karakter berdasarkan input sekuens karakter yang diberikan"]},{"cell_type":"code","metadata":{"id":"AnhZ16KsXrdc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"30514845-9642-4c1c-b1ed-883b55b887d5"},"source":["!pip install tensorflow-gpu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ERD4CSQS43bS","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.callbacks import LambdaCallback\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import TimeDistributed\n","from tensorflow.keras.layers import Reshape\n","from tensorflow.keras.optimizers import RMSprop, Adam\n","from tensorflow.keras.utils import get_file\n","\n","import numpy as np\n","import random\n","import sys\n","import io"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nJDSNEbi5KaX"},"source":["# Text Data\n","Untuk memulainya, kita perlu memiliki data untuk melatih model kita. Anda dapat menggunakan file teks apa pun yang Anda inginkan untuk proses ini\n","\n","di sini telah disediakan beberapa data text yang bisa digunakan"]},{"cell_type":"code","metadata":{"id":"rkhyOwmn8LtY","colab_type":"code","colab":{}},"source":["dataset = {\n","    'shakespeare'  : 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',\n","    'wonderland'   : 'https://www.gutenberg.org/cache/epub/11/pg11.txt',\n","    'harry'        : 'https://www.linguistik.uzh.ch/dam/jcr:169bff5c-ac13-457b-9acb-4fe7f1ad5cb0/Harry%20Potter%20and%20the%20Sorcerer.txt',\n","    'nietzsche'    : 'https://s3.amazonaws.com/text-datasets/nietzsche.txt',\n","    'frankenstein' : 'https://www.gutenberg.org/files/84/84-0.txt',\n","    'liriklagu'    : 'https://raw.githubusercontent.com/dhamirdesrul/Text-Generation/master/lagupeterpan.txt'\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2hN0SFj5NRR","colab_type":"text"},"source":["Pilih satu data"]},{"cell_type":"code","metadata":{"id":"OR-p4_t65EiT","colab_type":"code","colab":{}},"source":["# inisilisasi variable filename dengan file dataset\n","filename = ?? \n","path = get_file( filename.split('/')[-1], origin=filename)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qw9NuaG1DjAn","colab_type":"text"},"source":["# **Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"aTAhuDMq-Nqt","colab_type":"text"},"source":["Semua data akan dilakukan prapemrosesan, data tersebut akan dibersihkan seperti: \n","- Menghapus karakter yang tidak diperlukan\n","- lowercase"]},{"cell_type":"code","metadata":{"id":"fpuwR6VYDluW","colab_type":"code","colab":{}},"source":["# import regex\n","??\n","\n","kalimat = ''\n","with io.open(path, encoding='utf-8') as f:\n","    text = f.read().lower()\n","\n","# melakukan preprocessing dengan menghilangkan \"'\", \"\\n\", \".\", \"-\", \",\"\n","kalimat = ?? \n","text = kalimat\n","text[:250]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gfsGbEFn5R6k"},"source":["# Encoding\n","Jaringan saraf bekerja dengan angka, bukan karakter teks. Jadi kita perlu mengkonversi input karakter menjadi angka. \n","\n","Pertama, kita urutkan daftar unik semua karakter yang muncul dalam teks tersebut, kemudian gunakan fungsi enumerasi untuk mendapatkan angka yang mewakili karakter tersebut. \n","\n","Berikutnya buat kamus yang menyimpan kunci dan nilai, atau karakter dan angka yang mewakili mereka."]},{"cell_type":"code","metadata":{"id":"lC5GYYNc5RT-","colab_type":"code","colab":{}},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = ??\n","indices_char = ??\n","# indices_char"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Co-Dcee-_NFE","colab_type":"text"},"source":["# Sequence Building\n","\n","Di sini kita set bahwa maksimum sequence dari karakter input adalah 40\n","\n","Untuk itu, kita harus memotong semua text dalam bentuk sekuens semi-redundan sepanjang 40 karakter. Kita gunakan nilai redundansi sebesar 3 karakter\n","\n","artinya, misal kita memiliki teks: `\"saya suka makan nasi\"`, kemudian kita buat sekuens semi-redundan dengan panjang 5 dan redundansi 2, maka kita akan memiliki\n","* `'saya '` dengan target `'aya s'`\n","* `'ya su'` dengan target `'a suk'`\n","* `' suka'` dengan target `'suka '`\n","* `'uka m'` dengan target `'ka ma'`\n","* dan seterusnya\n"]},{"cell_type":"code","metadata":{"id":"rdiBnZdC5RRS","colab_type":"code","colab":{}},"source":["# cut the text in semi-redundant sequences of maxlen characters\n","?? \n","?? \n","sentences = []\n","next_chars = []\n","\n","for i in range(0, len(text) - maxlen, step):\n","    # memasukkan text ke dalam sentences\n","    ?? \n","    \n","    #memasukkan text selanjutnya ke dalam next_chars\n","    ?? \n","    \n","print('nb sequences:', len(sentences))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtN3FRiwAPeF","colab_type":"code","colab":{}},"source":["for i in range(10):\n","  print([sentences[i]],[next_chars[i]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2PjNCXnQAhMo","colab_type":"text"},"source":["Berikutnya kita buat data latih dan targetnya berupa vektor angka yang diambil dari dictionary berdasarkan kalimat sekuens yang sudah kita buat"]},{"cell_type":"code","metadata":{"id":"3Lw2Tg4253El","colab_type":"code","colab":{}},"source":["# print('Vectorization...')\n","# menginisialisasi x dan y berisikan matriks kosong sebesar 3x3 menggunakan sentences, maxlen, dan chars\n","\n","x = ?? \n","y = ?? \n","\n","\n","# melibatkan hasil encoding diatas\n","# mengisi x dengan nilai 1 berdasarkan jumlah index kalimat, index karakter, index karakter dalam char_indicies\n","??\n","        \n","\n","# mengisi y dengan nilai 1 berdasarkan jumlah index kalimat selanjutnya, index karakter selanjutnya, jumlah karakter selanjutnya\n","??\n","        \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9d-oAr5A9yf","colab_type":"text"},"source":["# LSTM Model\n","Sekarang kita coba bangun jaringan sederhana mengguankan 1 layer LSTM dengan ukuran output vektor 128. Setelah layer LSTM, kita tambahkan Layer Dense untuk memprediksi kelanjutan karakter dari 40 karakter input"]},{"cell_type":"markdown","metadata":{"id":"LCtaHrUpYxHc","colab_type":"text"},"source":["Many to Many RNN"]},{"cell_type":"markdown","metadata":{"id":"cbPwJqK5ZIKF","colab_type":"text"},"source":["![alt text](https://indoml.files.wordpress.com/2018/03/kind-many-to-many2.jpg)"]},{"cell_type":"code","metadata":{"id":"hhIbD-8j53Bt","colab_type":"code","colab":{}},"source":["#inisialisasi model dengan squential\n","model = Sequential()\n","# menambahkan model dengan LSTM sebanyak 256, input_shape diisi maxlen, panjang karakter, dan parameter return_sequences\n","model.add(LSTM(??))\n","model.add(LSTM(??))\n","\n","# menambahkan model dengan dense sebanyak panjang karakter dan aktivasi menggunakan softmax\n","model.add(TimeDistributed(Dense(??)))\n","\n","#menambahkan model dengan melakukan reshape dengan maxlen dan panjang karakter\n","model.add(Reshape((??)))\n","\n","#melakukan optimizer menggunakan 'adam' dengan learning rate sebesar 0.01\n","optimizer = Adam(lr=0.01)\n","# model akan di compile menggunakan parameter loss 'categorical_crossentropy' dan optimizer 'adam'\n","model.compile(??)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvBubvrzYBs7","colab_type":"code","colab":{}},"source":["# Menampilkan layer yang telah dibuat\n","from tensorflow.keras.utils import plot_model\n","plot_model(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYwLLUM5CPAm","colab_type":"text"},"source":["# Sample Probability Function\n","Berikut adalah helper function untuk melakukan sampling karakter output berdasarkan output probability dari softmax"]},{"cell_type":"code","metadata":{"id":"_VKGcWRB52_A","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","  \n","  \"\"\"\n","    \n","    Inputs:\n","    - preds: prediksi model\n","    - temperature: temperatur diisi dengan 1.0\n","    \n","    Outputs:\n","    Nilai probabilitas \n","    \"\"\"\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vaKAd0M0CbAj","colab_type":"text"},"source":["# Training Checkpoint\n","Berikutnya mari kita tambahkan sebuah callback pada fungsi training agar kita bisa melihat contoh hasil pembangkitan text yang dilakukan setiap 5 epoch"]},{"cell_type":"code","metadata":{"id":"rijJvqiB567O","colab_type":"code","colab":{}},"source":["def on_epoch_end(epoch, _):\n","  if epoch%5==0:\n","    # Function invoked at end of each epoch. Prints generated text.\n","    print('\\n---------------------------------------------------------------------')\n","    print('>>>>> Generating text after Epoch: %d' % epoch)\n","\n","    # mencari nilai random dari index 0 sampai jumlah text-maxlen-1\n","    start_index = random.randint(??) \n","    diversity = 0.7\n","    print('\\n>>>>> diversity:', diversity)\n","\n","    generated = ''\n","    # menginisialisasi sentence pada text dengan index [start_index: start_index + maxlen]\n","    sentence = text[start_index: start_index + maxlen]\n","    # menambahkan variable generate dengan value sentence\n","    generated += sentence\n","    print('>>>>> Generating with seed: \"' + sentence + '\"')\n","    sys.stdout.write(generated)\n","\n","    # input nilai a berdasarkan jumlah output karakter yang diinginkan\n","    a = 100\n","    for i in range(a):\n","        # menginisiasi x_pred menggunakan matrix 0 dengan ukuran 1x maxlen x panjang karakter\n","        x_pred = np.zeros((1, maxlen, len(chars)))\n","        # mengisi x_pred dengan nilai 1 berdasarkan index [0, index karakter, dan jumlah karakter]\n","        for t, char in enumerate(sentence):\n","            x_pred[??] = ??.\n","        \n","        # menginisialisasi preds dengan hasil prediksi model dengan parameter x_pred dan verbose=0 indeks 0\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        # menginisialisasi next_index dengan sampling karakter\n","        next_index = sample(preds[-1], diversity)\n","        # menginisialisasi next_char dengan karakter berdasarkan index dalam indicies_char index [next_char]\n","        next_char = indices_char[next_index]\n","        # menambahkan generated dengan  value next_char\n","        generated += next_char\n","        # menginisiasi sentence dengan value sentences dari index [1: ] ditambahkan dengan value next_char\n","        sentence = sentence[1:] + next_char\n","\n","        sys.stdout.write(next_char)\n","        sys.stdout.flush()\n","    print('\\n---------------------------------------------------------------------')\n","    print('>>>>> Continuing training')\n","        \n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fgscM3uqCklR","colab_type":"text"},"source":["# Training Process\n","\n","Sekarang tinggal kita latih model Text Generator kita"]},{"cell_type":"code","metadata":{"id":"h7zmN1YM564m","colab_type":"code","colab":{}},"source":["model.fit(x, y,\n","          batch_size=512,\n","          epochs=50,\n","          callbacks=[print_callback])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bD2PM4OLvku8","colab_type":"text"},"source":["# Testing Process\n","setelah model terlatih, mari kita uji untuk membangkitkan text sepanjang 400 karakter"]},{"cell_type":"code","metadata":{"id":"aXsUMA-eCBB1","colab_type":"code","colab":{}},"source":["input_kata = input()\n","index_kata = text.index(input_kata)\n","index_kata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lII3wCV65611","colab_type":"code","colab":{}},"source":["# start_index = random.randint(0, len(text) - maxlen - 1)\n","diversity = 0.7\n","print('\\n>>>>> diversity:', diversity)\n","\n","#menginisialisasi generated dengan string kosong\n","generated = ''\n","#menginisialisasi sentence denga text berdasarkan index [index_kata: index_kata + maxlen]\n","sentence = text[index_kata: index_kata + maxlen]\n","#menambahkan generated dengan value sentence\n","generated += sentence\n","print('>>>>> Generating with seed: \"' + sentence + '\"')\n","sys.stdout.write(generated)\n","\n","# input nilai a berdasarkan jumlah output karakter yang diinginkan\n","a = 200\n","for i in range(a):\n","    x_pred = np.zeros((1, maxlen, len(chars)))\n","    for t, char in enumerate(sentence):\n","        x_pred[0, t, char_indices[char]] = 1.\n","\n","    # menginisialisasi preds dengan hasil prediksi model dengan parameter x_pred dan verbose=0 indeks 0\n","    preds = model.predict(x_pred, verbose=0)[0]\n","    # menginisialisasi next_index dengan sampling karakter\n","    next_index = sample(preds[-1], diversity)\n","    # menginisialisasi next_char dengan karakter berdasarkan index dalam indicies_char index [next_char]\n","    next_char = indices_char[next_index]\n","    \n","    # menambahkan generated dengan  value next_char\n","    generated += next_char\n","    # menginisiasi sentence dengan value sentences dari index [1: ] ditambahkan dengan value next_char\n","    sentence = sentence[1:] + next_char\n","\n","    sys.stdout.write(next_char)\n","    sys.stdout.flush()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uB_ojCQ6zmKS","colab_type":"text"},"source":["<p>Copyright &copy; 2019 <a href=https://www.linkedin.com/in/andityaarifianto/>ADF</a> </p>"]}]}
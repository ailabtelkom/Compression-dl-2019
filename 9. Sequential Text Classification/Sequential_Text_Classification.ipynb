{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqwV7Qz_e6VR",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://anvaqta.id/headerai.jpg \"Compression.dl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs0Z-okE4HAq",
        "colab_type": "text"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dQdqFpH6PyO",
        "colab_type": "text"
      },
      "source": [
        "Lakukan import library yang akan digunakan selama proses klasifikasi artikel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynTXGkGRlGV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXjreOOGuhhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.models import model_from_json, load_model\n",
        "\n",
        "# Lakukan import fungsi train_test_split dari library sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re # regex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUM4wf_a4U4L",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Data Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b_Gl29-4jC3",
        "colab_type": "text"
      },
      "source": [
        "Hal pertama yang harus dilakukan adalah membaca atau menyimpan data yang akan digunakan dalam proses pembelajaran klasifikasi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDE3Tg0MukY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lakukan read data 'Data Training.xlsx' menggunakan fungsi read_excel pada library pandas\n",
        "# Beri nama kolom 0 dengan 'artikel' dan kolom 1 dengan 'label'\n",
        "data = ??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z_1jq6T5hfb",
        "colab_type": "text"
      },
      "source": [
        "Mari kita lihat data train yang akan kita gunakan!\n",
        "Dapat kita lihat pada data train yang baru saja disimpan masih mengandung huruf kapital dan karakter khusus ('.', '!', dll)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXdIrdAb5cpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hh7pkUX4ncd",
        "colab_type": "text"
      },
      "source": [
        "Setelah itu, lakukan pembersihan data train dengan mengubah seluruh huruf ke dalam huruf kecil dan membersihkannya dari karakter khusus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDZo82-uutC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex = r'[^a-z\\s]'\n",
        "\n",
        "# Ubah seluruh huruf dalam data artikel ke dalam lower case\n",
        "data['artikel'] = ??\n",
        "\n",
        "# Hapus seluruh simbol yang ada dan ganti dengan string kosong ('')\n",
        "data['artikel'] = ??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzXLNUQr5Rj4",
        "colab_type": "text"
      },
      "source": [
        "Mari bandingkan data yang telah dilakukan preprocessing dengan data yang masih mentah tadi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcEH0ONTvgbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaMVFFqp8fgU",
        "colab_type": "text"
      },
      "source": [
        "Lakukan tokenisasi terhadap seluruh data set yang telah dibersihkan dengan menggunakan tokenizer yang dimiliki oleh tensorflow keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBMImuokwSVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tentukan jumlah max_features (jumlah kata yang ingin digunakan pada setiap artikel)\n",
        "max_features = 500\n",
        "\n",
        "# Buat object Tokenizer() dari keras, \n",
        "# gunakan parameter num_words untuk membatasi kata yang ingin ditokenisasi pada tiap artikel\n",
        "# dan parameter split untuk menentukan pembatas tiap kata, (' ') = spasi\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "# Lakukan tokenisasi pada setiap artikel dengan tokenizer yang telah dibuat\n",
        "tokenizer.fit_on_texts(data['artikel'].values)\n",
        "\n",
        "# Ubah token menjadi sequence/angka-angka\n",
        "X = tokenizer.texts_to_sequences(data['artikel'].values)\n",
        "\n",
        "# Lakukan padding, jika jumlah kata dalam artikel tidak sebanyak max_features maka diisi dengan angka (0)\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL-mIkJg7LqQ",
        "colab_type": "text"
      },
      "source": [
        "# Pendefinisan Label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEfijs7r7Zyg",
        "colab_type": "text"
      },
      "source": [
        "Definisikan seluruh label artikel ke dalam sebuah list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQgQ24HTqRa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tentukan label yang digunakan\n",
        "labels = [??]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpjKC-7A7wwP",
        "colab_type": "text"
      },
      "source": [
        "Kemudian cek jumlah artikel yang terdapat pada setiap label untuk melihat data yang dimiliki bersifat imbalance atau tidak.\n",
        "Jika terlihat data yang memiliki jumlah 0, maka penamaan label kemungkinan ada yang salah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7N9Wjkrt5PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for label in labels:\n",
        "    print(label)\n",
        "    print(data[data['label']==label].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Agbd432ceT",
        "colab_type": "text"
      },
      "source": [
        "# Pembangunan Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKxy0s0FZrHJ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://indoml.files.wordpress.com/2018/03/kind-many-to-one2.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNCCwUUmZt-b",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-CJhx-8-cGo",
        "colab_type": "text"
      },
      "source": [
        "Langkah selanjutnya ialah membangun model klasifikasi dengan menggunakan metode LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrl__ufYw5hY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "# Inisiasi model dengan sequential\n",
        "model = Sequential()\n",
        "# menambahkan model dengan layer Embedding dengan input_dim sebesar max_features, output_dim sebesar embed_dim, dan input_length sebesar panjang X\n",
        "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "# menambahkan model dengan layer SpatialDropout1D sebesar 0.4\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "# menambahkan model dengan LSTM sebanyak lstm_out, dengan dropout dan recurrent_dropout sebesar 0.5, dan parameter return_sequences True\n",
        "model.add(LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
        "# menambahkan model dengan LSTM sebanyak lstm_out, dengan dropout dan recurrent_dropout sebesar 0.5, tanpa parameter return_sequences\n",
        "model.add(LSTM(lstm_out, dropout=0.5, recurrent_dropout=0.5))\n",
        "# menambahkan model dengan dense sebanyak jumlah label dan aktivasi menggunakan softmax\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "# model akan di compile menggunakan parameter loss 'categorical_crossentropy', optimizer 'adam' dan metrics accuracy\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2xlvS3BDwgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menampilkan layer yang telah dibuat\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJAZtlDp-vIy",
        "colab_type": "text"
      },
      "source": [
        "Untuk dapat menguji model yang telah dibangun, maka lakukan split (pembagian) data train menjadi dua data berbeda, yaitu data train dan data validasi. \n",
        "\n",
        "Gunakan data validasi sebesar 33% dari data yang dimiliki."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUM50cIpw-Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ubah data label menjadi variable dummy dengan menggunakan library pandas (pd.get_dummies())\n",
        "Y = ??\n",
        "# Lakukan split data menggunakan function train_test_split() pada sklearn \n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33hl2BeE_P1E",
        "colab_type": "text"
      },
      "source": [
        "Latih model dengan data train yang telah displit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAk3g7rnxHxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    epochs = 30, batch_size=batch_size, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G_YM7p9C0mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menampilkan grafik accuracy dan validation accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "# Tampilkan grafik yang telah diplot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJVNxUJEq-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menampilkan hasil evaluasi akhir\n",
        "score,acc = model.evaluate(X_val, Y_val, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikky-6RPAcHV",
        "colab_type": "text"
      },
      "source": [
        "# Pengujian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqqXgnMFAppW",
        "colab_type": "text"
      },
      "source": [
        "Input kalimat yang akan diuji dengan model yang telah dibangun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBPFZzFo1Maz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Input Kalimat\n",
        "#@markdown Kalimat diawali dan diakhiri tanda kutip (\" \")\n",
        "\n",
        "kalimat= \"  \"  #@param\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR6T2e45AyFH",
        "colab_type": "text"
      },
      "source": [
        "Lakukan pembersihan data terhadap inputan kalimat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJGeZOImDbsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ubah hasil inputan kalimat ke dalam bentuk lower case\n",
        "kalimat = ??\n",
        "\n",
        "# Hapus seluruh simbol dan ganti dengan string kosong (''), gunakan function re.sub\n",
        "kalimat = ??\n",
        "\n",
        "# Ubah hasil inputan kedalam list/array\n",
        "kalimat = [kalimat]\n",
        "\n",
        "print(kalimat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfnl7BrA6_J",
        "colab_type": "text"
      },
      "source": [
        "Jangan lupa lakukan tokenisasi terhadap inputan kalimat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDElE56EaVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ubah token menjadi sequence/angka2\n",
        "test_kalimat = tokenizer.texts_to_sequences(kalimat)\n",
        "\n",
        "# Lakukan padding, jika jumlah kata dalam artikel tidak sebanyak max_features maka diisi dengan angka (0)\n",
        "test_kalimat = pad_sequences(test, maxlen=X.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyK-zMldBGgp",
        "colab_type": "text"
      },
      "source": [
        "Ayo prediksi label dari inputan kalimat!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq4vNmoRE0r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ubah kalimat yang ingin diuji kedalam bentuk vector\n",
        "vector = np.array([test.flatten()])\n",
        "\n",
        "# Prediksi label dari kalimat tersebut menggunakan function model.predict_classes()\n",
        "y = ??\n",
        "\n",
        "print(labels[y[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdMPQtCSBUv4",
        "colab_type": "text"
      },
      "source": [
        "# Penyimpanan Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQOJQxTCBX7E",
        "colab_type": "text"
      },
      "source": [
        "Simpan model ke dalam file dengan format .h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMkqz6EjdJpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_model(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON8k5ckABko5",
        "colab_type": "text"
      },
      "source": [
        "Unduh model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zmWJ5l9gRa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVkWYHJZB2Uj",
        "colab_type": "text"
      },
      "source": [
        "Gunakan code di bawah untuk memuat ulang model (load model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISDeg2zgdJUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = load_model(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}